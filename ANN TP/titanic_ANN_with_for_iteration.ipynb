{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   \n",
       "0            1         0       3  \\\n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp   \n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1  \\\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", dtype={\"Age\": np.float64})\n",
    "test = pd.read_csv(\"test.csv\", dtype={\"Age\": np.float64})\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor = [\n",
    "    \"Age\",\n",
    "    \"Fare\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"FamilySize\",\n",
    "    \"male\",\n",
    "    \"female\",\n",
    "    \"pclass_1\",\n",
    "    \"pclass_2\",\n",
    "    \"pclass_3\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_data(titanic_data):\n",
    "    #titanic_data.Sex = titanic_data.Sex.replace(['male', 'female'], [0, 1])\n",
    "    titanic_data.Embarked = titanic_data.Embarked.fillna(\"S\")\n",
    "    #titanic_data.Embarked = titanic_data.Embarked.replace(['C', 'S', 'Q'], [0, 1, 2])\n",
    "    titanic_data.Age = titanic_data.Age.fillna(titanic_data.Age.median())\n",
    "\n",
    "    # Trying to add FamilySize\n",
    "    titanic_data['FamilySize'] = titanic_data['SibSp'] + \\\n",
    "        titanic_data['Parch'] + 1\n",
    "\n",
    "    # add Male & Female one-hot-encoding\n",
    "    sex_dummy = pd.get_dummies(titanic_data.Sex)\n",
    "    titanic_data['male'] = sex_dummy.male\n",
    "    titanic_data['female'] = sex_dummy.female\n",
    "\n",
    "    # add Embarked one-hot-encoding\n",
    "    embarked_dummy = pd.get_dummies(titanic_data.Embarked)\n",
    "    titanic_data['embarked_C'] = embarked_dummy.C\n",
    "    titanic_data['embarked_S'] = embarked_dummy.S\n",
    "    titanic_data['embarked_Q'] = embarked_dummy.Q\n",
    "\n",
    "    # add Pclass one-hot-encoding\n",
    "    pclass_dummy = pd.get_dummies(titanic_data.Pclass)\n",
    "    titanic_data['pclass_1'] = pclass_dummy[1]\n",
    "    titanic_data['pclass_2'] = pclass_dummy[2]\n",
    "    titanic_data['pclass_3'] = pclass_dummy[3]\n",
    "\n",
    "    # Cabin\n",
    "    titanic_data.Cabin = titanic_data.Cabin.fillna(\"N\")\n",
    "    titanic_data['CabinDeck'] = titanic_data.Cabin.str.slice(0, 1)\n",
    "    cabindeck_dummy = pd.get_dummies(titanic_data.CabinDeck)\n",
    "\n",
    "    titanic_data['CabinDeck_A'] = cabindeck_dummy.A\n",
    "    titanic_data['CabinDeck_B'] = cabindeck_dummy.B\n",
    "    titanic_data['CabinDeck_C'] = cabindeck_dummy.C\n",
    "    titanic_data['CabinDeck_D'] = cabindeck_dummy.D\n",
    "    titanic_data['CabinDeck_E'] = cabindeck_dummy.E\n",
    "    titanic_data['CabinDeck_F'] = cabindeck_dummy.F\n",
    "    titanic_data['CabinDeck_G'] = cabindeck_dummy.G\n",
    "    titanic_data['CabinDeck_NaN'] = cabindeck_dummy.N\n",
    "\n",
    "    titanic_data.Fare = titanic_data.Fare.fillna(titanic_data.Fare.median())\n",
    "\n",
    "    return titanic_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1    female\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head().Sex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bensb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "correct_train = correct_data(train).sample(frac=1)\n",
    "\n",
    "trainX = correct_train[predictor].values\n",
    "trainY = correct_train.Survived.values\n",
    "\n",
    "\n",
    "aiot4 = MLPClassifier(activation='tanh', solver='lbfgs', max_iter=5000,\n",
    "                      alpha=1e-4, hidden_layer_sizes=(15, 8), random_state=4)\n",
    "aiot4.fit(trainX, trainY)\n",
    "print(\"Test set score: {:.3f}\".format(aiot4.score(trainX, trainY)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n",
      "[50.0 10.5 0 0 1 False True False True False]\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor max_iter in [500, 1000, 2000]:\\n    for alpha in [0.0001, 0.00001, 0.000003]:\\n        for solver in [\"lbfgs\", \"sgd\", \"adam\"]:\\n            for activation in [\"identity\", \"logistic\", \"tanh\", \"relu\"]:\\n                for hidden_layer_sizes in [(15, 8),(10, 8),(10, 8,3)]:\\n                    aiot4 = MLPClassifier(activation=activation, solver=solver, max_iter=max_iter,\\n                                        alpha=alpha, hidden_layer_sizes=hidden_layer_sizes, random_state=4)\\n                    aiot4.fit(trainX, trainY)\\n                    print(\"Iterations :\", max_iter,\"alpha :\", alpha,\"solver :\", solver,\"activation\", activation,\"hidden_layer_sizes\", hidden_layer_sizes)\\n                    print(\"Test set score: {:.3f}\".format(aiot4.score(trainX, trainY)))\\n                     \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for max_iter in [500, 1000, 2000]:\n",
    "    for alpha in [0.0001, 0.00001, 0.000003]:\n",
    "        for solver in [\"lbfgs\", \"sgd\", \"adam\"]:\n",
    "            for activation in [\"identity\", \"logistic\", \"tanh\", \"relu\"]:\n",
    "                for hidden_layer_sizes in [(15, 8),(10, 8),(10, 8,3)]:\n",
    "                    aiot4 = MLPClassifier(activation=activation, solver=solver, max_iter=max_iter,\n",
    "                                        alpha=alpha, hidden_layer_sizes=hidden_layer_sizes, random_state=4)\n",
    "                    aiot4.fit(trainX, trainY)\n",
    "                    print(\"Iterations :\", max_iter,\"alpha :\", alpha,\"solver :\", solver,\"activation\", activation,\"hidden_layer_sizes\", hidden_layer_sizes)\n",
    "                    print(\"Test set score: {:.3f}\".format(aiot4.score(trainX, trainY)))\n",
    "                     \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(13,18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0828b2e99f1c52001b429b0d7eac91212fe912a694384e4dfcc0ca31cd59103"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
